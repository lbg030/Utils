{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core-Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first =[45.78, 44.66, 47.42, 43.27, 46.7]\n",
    "second = [53.16, 53.0, 58.49, 55.0, 55.57]\n",
    "third = [57.8, 58.02, 63.36, 62.74]\n",
    "fourth = [65.31, 65.19, 67.5, 71.32]\n",
    "fifth = [72.03, 73.1, 74.5, 72.97]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_mean = sum(first) / 5\n",
    "second_mean = sum(second) / 5\n",
    "third_mean = sum(third) / 4\n",
    "fourth_mean = sum(fourth) / 4\n",
    "fifth_mean = sum(fifth) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot([\"1K\",\"2K\",\"3K\",\"4K\",\"5K\"], [first_mean,second_mean,third_mean, fourth_mean, fifth_mean])\n",
    "plt.xlabel('number of Data (K)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_f1 = [[0.5020, 0.3265, 0.2425], [0.6170, 0.5261, 0.4990], [0.6665, 0.6912,0.6024], [0.7140, 0.7527,0.7039], [0.7754, 0.7607,0.7547]]\n",
    "first_acc = [[0.5403, 0.3612,0.3313 ], [0.6418, 0.5582, 0.5164], [0.6776, 0.6985,0.6090], [0.7194, 0.7552,0.6985], [0.7701, 0.7672,0.7582]]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lst = [\"100\",\"200\",\"300\",\"400\",\"500\"]\n",
    "plt.plot(lst, [sum(first_f1[i])/3 for i in range(5)], label = 'F1_Score')\n",
    "plt.plot(lst,  [sum(first_acc[i])/3 for i in range(5)],label = 'Acc')\n",
    "plt.xlabel('number of Data')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Data | hz : 240 / bz : 240 / chem : 216 / yd : 124\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_f1 = [[0.5021],[0.5548],[],[],[]]\n",
    "first_acc = [[0.5403],[0.5701],[],[],[]]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "lst = [\"100\",\"200\",\"300\",\"400\",\"500\"]\n",
    "plt.plot(lst, [sum(first_f1[i]) for i in range(5)], label = 'F1_Score')\n",
    "plt.plot(lst,  [sum(first_acc[i]) for i in range(5)],label = 'Acc')\n",
    "plt.xlabel('number of Data')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Data | hz : 240 / bz : 240 / chem : 216 / yd : 124\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ibyeong-gwon/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/ibyeong-gwon/opt/anaconda3/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6.3285e-01, 9.9997e-02, 7.3522e-02, 3.4023e+00, 5.1665e-02, 1.2602e-01,\n",
      "        3.5051e-03, 6.4733e-01, 1.6601e-01, 5.1145e-02, 1.7686e-01, 6.9418e-01,\n",
      "        1.1602e-01, 6.3946e-02, 3.9355e-01, 3.3334e-01, 0.0000e+00, 3.5495e-01,\n",
      "        1.6508e-01, 1.0070e-01, 8.2040e-02, 4.8783e-02, 2.9480e-02, 1.6359e-01,\n",
      "        6.3229e-03, 9.1938e-02, 1.9311e-01, 1.1069e-02, 0.0000e+00, 9.3937e-02,\n",
      "        8.4073e-01, 3.1671e-01, 2.3240e-01, 1.5725e-01, 4.0225e-02, 0.0000e+00,\n",
      "        4.2473e-02, 2.6368e-02, 1.0361e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.4955e-01, 1.6936e-01, 1.9148e-02, 1.6006e-02, 4.3603e-01, 1.3452e-01,\n",
      "        1.3681e-02, 4.1662e-02, 1.7506e-01, 7.4728e-02, 3.5487e-02, 2.0051e-03,\n",
      "        3.5205e+00, 2.8677e-02, 2.1723e+00, 6.5758e-02, 6.1024e-01, 2.0793e-02,\n",
      "        1.5252e-01, 8.0125e-03, 6.6079e-02, 1.2000e-01, 9.4927e-02, 0.0000e+00,\n",
      "        7.1000e-01, 1.1767e-02, 6.4279e-03, 1.5329e-02, 7.2368e-02, 5.2144e-01,\n",
      "        5.8086e-01, 2.1539e-02, 4.0034e-03, 1.7422e-02, 7.2139e-02, 0.0000e+00,\n",
      "        8.3033e-03, 9.4017e-02, 2.2015e-03, 8.3026e-01, 9.1784e-01, 0.0000e+00,\n",
      "        2.6779e-01, 2.5304e-02, 1.2945e-01, 2.2972e-02, 7.1544e-02, 0.0000e+00,\n",
      "        3.7144e-02, 9.4482e-02, 4.0650e-03, 9.8897e-02, 1.0686e+00, 0.0000e+00,\n",
      "        7.9508e-01, 3.5257e-03, 0.0000e+00, 7.5818e-03, 0.0000e+00, 2.1738e-01,\n",
      "        6.9597e-02, 5.1583e-01, 2.4811e+00, 2.9025e+00, 1.5464e-02, 6.2560e-03,\n",
      "        2.1285e-01, 0.0000e+00, 1.0066e-03, 0.0000e+00, 2.7596e-01, 4.4652e-01,\n",
      "        5.6537e-02, 0.0000e+00, 3.2121e-03, 2.2731e-01, 5.1582e-01, 8.7825e-03,\n",
      "        6.0184e-01, 1.3644e-01, 1.5059e-03, 1.8297e-01, 6.5676e-02, 1.9269e-02,\n",
      "        5.7584e-01, 5.0379e-02, 2.6638e-01, 2.7102e-02, 2.2149e-01, 3.2539e-04,\n",
      "        2.1507e-01, 2.7631e-02, 1.6945e-02, 5.8339e-01, 1.7654e-01, 2.7630e-03,\n",
      "        1.3003e-01, 1.8794e-01, 6.6829e-02, 3.7198e-01, 9.8115e-04, 1.2168e-01,\n",
      "        1.1047e-01, 2.9826e-01, 6.8865e-02, 1.6318e+00, 2.1084e-01, 1.8733e+00,\n",
      "        0.0000e+00, 1.2566e-01, 0.0000e+00, 1.9697e-02, 6.6483e-02, 2.3812e-01,\n",
      "        5.9905e-01, 1.2232e-01, 2.8810e-01, 1.6859e-02, 2.2204e+00, 2.5309e-01,\n",
      "        1.0939e-01, 1.5269e-01, 3.3503e-02, 1.4322e-01, 3.2109e-01, 1.9489e-02,\n",
      "        2.6293e-02, 1.0649e-01, 5.4687e-03, 2.1312e-01, 1.3044e-01, 7.3454e-03,\n",
      "        1.1342e-01, 2.5685e-01, 4.3343e-02, 2.9373e-02, 2.9573e-02, 0.0000e+00,\n",
      "        1.3999e-01, 8.2673e-03, 3.0239e-01, 4.4938e-01, 3.1378e-02, 1.2298e-01,\n",
      "        8.8703e-04, 7.9680e-02, 4.2857e-02, 3.8010e-01, 4.0582e-02, 2.6019e-02,\n",
      "        9.2580e-01, 3.0886e+00, 2.8839e-03, 3.2103e-01, 2.2630e-03, 2.2645e-01,\n",
      "        1.0562e-01, 1.7602e-03, 3.0172e-04, 5.1070e-01, 2.8151e-01, 1.8962e-01,\n",
      "        1.5088e-03, 1.8183e-01, 1.3838e-01, 2.7598e-02, 5.7869e-01, 5.5328e-01,\n",
      "        3.7908e-03, 5.2739e-02, 0.0000e+00, 2.1632e-01, 5.3466e-02, 2.1120e-01,\n",
      "        4.7307e-01, 9.6677e-02, 8.7002e-02, 2.6735e-02, 7.7799e-02, 5.4519e-02,\n",
      "        7.1379e-01, 1.1309e-01, 1.1820e-01, 2.1056e-01, 2.1183e-02, 3.3713e-02,\n",
      "        2.8218e-01, 1.1599e-01, 1.2673e-01, 2.2868e-01, 1.9634e-02, 2.6700e-02,\n",
      "        2.1474e-02, 8.6461e-02, 1.1222e+00, 2.5445e-01, 2.9624e-02, 4.4608e-01,\n",
      "        5.0818e-02, 2.6733e-02, 2.7810e-01, 6.5300e-02, 2.8110e-01, 1.8334e-01,\n",
      "        3.6314e-03, 3.7260e-03, 2.9366e-01, 1.0926e-01, 3.0954e-01, 8.8740e-01,\n",
      "        0.0000e+00, 4.7880e-02, 1.5257e-01, 2.7832e-01, 2.2631e-01, 1.5056e-01,\n",
      "        1.3428e-01, 3.2261e-01, 2.4779e-02, 0.0000e+00, 2.3562e-01, 3.5192e-02,\n",
      "        1.2142e-02, 8.2871e-01, 0.0000e+00, 1.0527e-01, 1.4124e+00, 7.5120e-02,\n",
      "        1.9017e-01, 5.8292e-02, 3.1258e-02, 5.4622e-02, 3.1254e-03, 1.4207e-01,\n",
      "        1.6598e+00, 3.0309e-01, 3.1226e-01, 4.7779e-03, 4.4069e-03, 4.3948e-03,\n",
      "        2.4624e-01, 7.2049e-02, 7.7386e-02, 2.9630e-02, 0.0000e+00, 2.9396e-03,\n",
      "        7.6991e-02, 3.1150e-02, 9.2089e-02, 0.0000e+00, 0.0000e+00, 2.5417e-01,\n",
      "        3.3996e-01, 3.2692e-03, 4.7180e-03, 6.0063e-02, 2.5370e-01, 5.6136e-01,\n",
      "        2.1226e+00, 8.5821e-04, 3.5527e-01, 7.2301e-03, 7.8660e-02, 1.8362e-03,\n",
      "        8.2227e-02, 1.3886e-01, 7.3002e-03, 1.0486e-02, 2.9234e-02, 0.0000e+00,\n",
      "        1.0551e-01, 1.2326e-02, 5.7343e-01, 1.4822e-03, 5.3560e-04, 6.8521e-03,\n",
      "        1.9266e-01, 6.8178e-01, 1.0534e+00, 5.0855e-01, 2.2300e-01, 3.7581e-02,\n",
      "        9.6722e-02, 2.2023e-01, 0.0000e+00, 1.0702e-02, 1.3444e-01, 4.8390e-02,\n",
      "        3.3721e-02, 3.1261e-03, 1.3080e-01, 0.0000e+00, 4.5466e-01, 3.3326e-03,\n",
      "        2.2771e+00, 3.6009e-01, 1.7557e-01, 1.3524e-03, 0.0000e+00, 2.5934e-02,\n",
      "        5.5281e-01, 1.2227e+00, 1.6531e+00, 7.5475e-01, 5.2739e-02, 2.6328e-01,\n",
      "        0.0000e+00, 6.5066e-01, 0.0000e+00, 2.3581e-01, 2.8820e-03, 6.7775e-03,\n",
      "        1.5211e-01, 5.9334e-03, 2.9547e-01, 2.8588e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.0347e+00, 1.8405e-01, 4.0584e-01, 3.7739e-02, 4.9684e-02, 2.9397e-01,\n",
      "        2.0259e-01, 2.6561e-03, 9.9141e-01, 1.3937e-01, 4.8671e-01, 3.4130e-02,\n",
      "        0.0000e+00, 6.6552e-02, 3.3997e-02, 8.0883e-02, 1.7047e-01, 3.4234e-02,\n",
      "        1.4444e-01, 1.3103e-01, 8.9957e-02, 7.2076e-03, 3.0767e-01, 5.8966e-01,\n",
      "        4.0118e-02, 4.7614e-01, 2.1480e-03, 1.4854e-03, 1.1706e-02, 1.8365e-01,\n",
      "        2.8066e-02, 8.4398e-02, 3.1432e-01, 4.3281e-01, 4.9881e-02, 2.7413e-03,\n",
      "        3.7163e-01, 1.5789e-01, 7.8685e-01, 0.0000e+00, 3.5533e-03, 2.8519e+00,\n",
      "        0.0000e+00, 1.4304e-01, 3.5617e-01, 2.5451e-03, 3.8441e-01, 2.0780e-03,\n",
      "        5.7890e-01, 3.1088e-02, 2.1595e-02, 2.5624e-01, 1.4587e-01, 1.6623e-01,\n",
      "        9.7888e-03, 4.5969e-02, 1.3963e-01, 8.7104e-02, 2.5673e-01, 1.3104e-02,\n",
      "        1.7899e-01, 0.0000e+00, 0.0000e+00, 3.5585e-01, 3.2480e-01, 0.0000e+00,\n",
      "        2.0332e+00, 0.0000e+00, 9.5333e-03, 1.9962e-01, 1.7553e-03, 9.7201e-03,\n",
      "        5.0809e-02, 3.8019e-02, 2.3227e-01, 6.4715e-01, 1.7249e-01, 0.0000e+00,\n",
      "        1.4014e-01, 0.0000e+00, 6.8747e-02, 1.7759e-02, 3.5442e-02, 4.4700e-01,\n",
      "        1.8281e-02, 0.0000e+00, 5.1968e-02, 5.0637e-01, 5.7808e-01, 1.3193e+00,\n",
      "        4.6941e-01, 9.7508e-02, 3.6285e-01, 8.1963e-01, 0.0000e+00, 1.0663e-01,\n",
      "        1.8589e-02, 3.8796e-01, 2.7709e-02, 6.9590e-02, 1.5798e+00, 1.5488e-01,\n",
      "        5.6982e-02, 2.4856e-01, 2.0922e-03, 5.4316e-02, 2.4739e-03, 2.1137e-01,\n",
      "        0.0000e+00, 3.8900e-02, 1.2581e-01, 1.6321e-01, 7.2789e-03, 3.1868e-02,\n",
      "        4.6856e-03, 3.3589e-02, 1.0807e-01, 1.0909e-01, 0.0000e+00, 8.0124e-02,\n",
      "        1.5953e-01, 1.2537e-01, 5.0334e-01, 1.6191e-02, 3.8893e-01, 0.0000e+00,\n",
      "        2.5402e-01, 1.1068e-01, 4.8991e-01, 1.7403e-03, 4.8475e-02, 1.1516e+00,\n",
      "        2.8326e-02, 6.3243e-02, 0.0000e+00, 0.0000e+00, 2.2014e-01, 1.8175e-02,\n",
      "        2.2095e-02, 2.7483e-01, 1.6287e-02, 7.2954e-02, 6.9945e-02, 4.3118e-01,\n",
      "        7.6891e-02, 3.0060e-01, 2.5209e-02, 3.4227e-02, 8.1475e-02, 9.6780e-02,\n",
      "        5.9968e-02, 6.1281e-02])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from PIL import Image\n",
    "\n",
    "# Load the pretrained model\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Use the model object to select the desired layer\n",
    "layer = model._modules.get('avgpool')\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Image transforms\n",
    "scaler = transforms.Resize((224, 224))\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "to_tensor = transforms.ToTensor()\n",
    "\n",
    "def get_vector(image_name):\n",
    "    # 1. Load the image with Pillow library\n",
    "    img = Image.open(image_name)\n",
    "    # 2. Create a PyTorch Variable with the transformed image\n",
    "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0))\n",
    "    # 3. Create a vector of zeros that will hold our feature vector\n",
    "    #    The 'avgpool' layer has an output size of 512\n",
    "    my_embedding = torch.zeros(512)\n",
    "    # 4. Define a function that will copy the output of a layer\n",
    "    def copy_data(m, i, o):\n",
    "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
    "    # 5. Attach that function to our selected layer\n",
    "    h = layer.register_forward_hook(copy_data)\n",
    "    # 6. Run the model on our transformed image\n",
    "    model(t_img)\n",
    "    # 7. Detach our copy function from the layer\n",
    "    h.remove()\n",
    "    # 8. Return the feature vector\n",
    "    return my_embedding.detach()\n",
    "\n",
    "img = \"/Users/ibyeong-gwon/Desktop/fst/data/bz/raw_image/211201-AT6T31EH-M229_inpaint_1 ADR_W0.9_H1.3_BS.jpg\"\n",
    "a= (get_vector(img))\n",
    "\n",
    "# def copy_data(m, i, o):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "39523b5506b09c1341afcde84115bb5b8a9de94ca361b7e653f8ee467cc4d43c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
